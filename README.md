# FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

# Sprint 1 - Reply 

## Nome do grupo

## üë®‚Äçüéì Integrantes: 
- <a href="">Alice C. M. Assis - RM 566233</a>
- <a href="">Leonardo S. Souza - RM 563928</a>
- <a href="">Lucas B. Francelino - RM 561409</a> 
- <a href="">Pedro L. T. Silva - RM 561644</a> 
- <a href="">Vitor A. Bezerra - RM 563001</a>

## üë©‚Äçüè´ Professores:
### Tutor(a) 
- <a href="https://www.linkedin.com/company/inova-fusca">Lucas Gomes Moreira</a>
### Coordenador(a)
- <a href="https://www.linkedin.com/company/inova-fusca">Andr√© Godoi Chiovato</a>


## üìú Descri√ß√£o

Este projeto visa o desenvolvimento de uma solu√ß√£o com foco em controle inteligente de processos, monitoramento, dashboards, alertas autom√°ticos e sistemas de predi√ß√£o. Com isso, busca ajudar seus clientes a alcan√ßarem excel√™ncia operacional, digitalizando seus ambientes e integrando dispositivos f√≠sicos e digitais para gerar dados e insights valiosos em tempo real.

## üõ† Tecnologias utilizadas
- Python
- NumPy
- Pandas
- Matplotlib
- Scipy
- Seaborn
- C++
- Docker
- Oracle Database / PostgreSQL / Amazon RDS ou Firebase
- MqTT
- TensorFlow / PyTorch

## Considera√ß√µes

**Como os dados ser√£o coletados a partir de sensores?**

**R:** Os dados ser√£o coletados a partir de sensores conectados a um ESP32 utilizando o protocolo MQTT. O ESP32 atuar√° como um cliente MQTT, publicando os dados dos sensores em t√≥picos espec√≠ficos. O servidor MQTT, que pode ser hospedado em um servi√ßo de nuvem ou em um servidor local, receber√° essas mensagens e as encaminhar√° para uma fila a qual distribuir√° para os servi√ßos inscritos.

**Onde os dados ser√£o armazenados?**

**R:** Os dados ser√£o armazenados em um banco de dados em nuvem utilizando Amazon RDS (PostgreSQL) para dados estruturados (como m√©tricas de sensores e logs) e Amazon S3 para dados brutos e arquivos tempor√°rios.
Por que essa escolha?
Escalabilidade Autom√°tica: O Amazon RDS ajusta capacidade conforme a demanda sem downtime, crucial para linhas de produ√ß√£o com picos de opera√ß√£o.
Alta Disponibilidade: Replica√ß√£o multi-AZ garante 99,99% de uptime (SLA AWS), evitando paradas n√£o planejadas.
Integra√ß√£o com IA: Compatibilidade nativa com servi√ßos AWS como Lambda e SageMaker, facilitando a implementa√ß√£o de modelos de ML.
Custo-Benef√≠cio: Amazon S3 armazena dados brutos a baixo custo (US$ 0,023/GB/m√™s), enquanto RDS oferece backups automatizados gratuitos.

**Como ser√° feita a integra√ß√£o com modelos de IA?**

**R:** A integra√ß√£o com modelos de IA ser√° realizada atrav√©s de APIs RESTful. Os dados coletados dos sensores ser√£o enviados para um servi√ßo de backend respons√°vel por executar os modelos de IA, que poder√£o ser implementados localmente em Python (utilizando bibliotecas como TensorFlow ou PyTorch) ou utilizando plataformas de IA na nuvem, de acordo com a necessidade de escalabilidade e desempenho do projeto.

Entre as solu√ß√µes em nuvem consideradas para a execu√ß√£o dos modelos est√£o:
- Vertex AI (Google Cloud): Ideal para treinar, implantar e gerenciar modelos de Machine Learning em escala, com integra√ß√£o nativa ao BigQuery e pipelines automatizados.

- AWS AI (Amazon SageMaker): Permite treinar e implantar modelos rapidamente com suporte para modelos customizados e otimizados, al√©m de oferecer auto escalonamento e monitoramento.

- OpenAI (ChatGPT API): Pode ser usado para an√°lises baseadas em linguagem natural, gera√ß√£o de insights automatizados ou intera√ß√£o com usu√°rios de forma inteligente.

O sistema escolher√° a melhor plataforma com base na natureza do modelo, nos requisitos de lat√™ncia e custo, e na integra√ß√£o com o restante da arquitetura (Google Cloud, AWS ou OpenAI). Os resultados das previs√µes ser√£o enviados de volta ao sistema, podendo ser armazenados no banco de dados, visualizados em dashboards ou utilizados para acionar alertas autom√°ticos.

Fizemos uma estimativa de custo utilizando um cen√°rio hipot√©tico de uso para os servi√ßos da Amanzon e Google e Open AI.

üíª AWS AI (Amazon SageMaker)

1. Computa√ß√£o
- Inst√¢ncia: ml.g4dn.xlarge
- Dura√ß√£o di√°ria: 6 horas
- Dias de uso no m√™s: 20
- Total de horas: 6 horas/dia √ó 20 dias = 120 horas
- Custo por hora: USD 0,7364
- Custo total de computa√ß√£o: 120 horas √ó USD 0,7364 = USD 88,368

2. Armazenamento
- Tipo de armazenamento: SSD de uso geral
- Tamanho: 5 GB
- Custo por GB/m√™s: USD 0,1125
- Custo total de armazenamento: 5 GB √ó USD 0,1125 = USD 0,5625
- Total mensal estimado: USD 88,93

üíª Vertex AI (Google Cloud)

1. Computa√ß√£o
- Inst√¢ncia: n1-standard-8 com GPU NVIDIA T4
- Dura√ß√£o di√°ria: 6 horas
- Dias de uso no m√™s: 20
- Total de horas: 6 horas/dia √ó 20 dias = 120 horas
- Custo por hora:
  - n1-standard-8: USD 0,379
  - GPU NVIDIA T4: USD 0,35
  - Total por hora: USD 0,729
- Custo total de computa√ß√£o: 120 horas √ó USD 0,729 = USD 87,48

2. Armazenamento
- Tipo de armazenamento: SSD padr√£o
- Tamanho: 5 GB
- Custo por GB/m√™s: USD 0,17
- Custo total de armazenamento: 5 GB √ó USD 0,17 = USD 0,85
- Total mensal estimado: USD 88,33

üíª OpenAI (ChatGPT API)

1. C√°lculo de Tokens
- Chamadas por dia: 6 horas/dia √ó 10 chamadas/hora = 60 chamadas/dia
- Chamadas por m√™s: 60 chamadas/dia √ó 20 dias = 1.200 chamadas/m√™s
- Tokens de entrada por m√™s: 1.200 chamadas √ó 500 tokens = 600.000 tokens
- Tokens de sa√≠da por m√™s: 1.200 chamadas √ó 500 tokens = 600.000 tokens

 2. GPT-4.5
- Custo por 1.000 tokens de entrada: USD 0,075
- Custo por 1.000 tokens de sa√≠da: USD 0,15
- Custo de entrada: 600.000 tokens √ó (USD 0,075 / 1.000) = USD 45,00
- Custo de sa√≠da: 600.000 tokens √ó (USD 0,15 / 1.000) = USD 90,00
- Total mensal estimado: USD 135,00

Conclus√£o: Os custos da Amazon e Google s√£o aproximados, mas os custos da Open AI s√£o significativamente mais elevados.

**Onde ocorrer√° o processamento?**

**R:** O processamento dos dados coletados dos sensores ocorrer√° em um servidor local ou na nuvem, dependendo da arquitetura escolhida. O uso de cont√™ineres Docker permitir√° que o sistema seja facilmente escal√°vel e port√°til, facilitando a implementa√ß√£o em diferentes ambientes. A escolha entre processamento local ou na nuvem depender√° das necessidades espec√≠ficas da empresa, da infraestrutura dispon√≠vel e preocupa√ß√£o com o sigilo dos dados.

## Requisitos T√©cnicos e Funcionais

1) Linguagens e ferramentas adequadas para an√°lise de dados e Machine Learning

- Python: Linguagem de programa√ß√£o amplamente utilizada para an√°lise de dados e Machine Learning, com bibliotecas como NumPy, Pandas, Matplotlib e Scipy.

2) Como os dados ser√£o coletados, incluindo o tipo de coleta (simulada ou planejada via sensores como ESP32), armazenados e processados?

- Coleta de dados: Os dados ser√£o coletados a partir de sensores conectados a um ESP32 utilizando o protocolo MQTT. O ESP32 atuar√° como um cliente MQTT, publicando os dados dos sensores em t√≥picos espec√≠ficos. O servidor MQTT, que pode ser hospedado em um servi√ßo de nuvem ou em um servidor local, receber√° essas mensagens e as encaminhar√° para uma fila a qual distribuir√° para os servi√ßos inscritos. Um desses servi√ßos ser√° o de armazenagem de dados, que cuidar√° de sua armazenagem em um dos bancos de dados citados anteriormente.

3) Qual √© a justificativa para a escolha de um banco de dados local ou na n√∫vem? Qual √© a sua escabilidade e viabilidade em rela√ß√£o ao projeto?

- A escolha entre um banco de dados local ou na nuvem deve considerar as necessidades espec√≠ficas do projeto, a infraestrutura dispon√≠vel e o n√≠vel de exig√™ncia quanto disponibilidade dos dados.

- Banco de dados local:
    A implementa√ß√£o local demanda um investimento inicial elevado, com custos associados √† aquisi√ß√£o de servidores, infraestrutura de TI e m√£o de obra especializada para instala√ß√£o e manuten√ß√£o. Al√©m disso, a         escalabilidade tende a ser limitada, exigindo novos aportes sempre que for necess√°rio expandir a capacidade. No entanto, pode apresentar melhor desempenho em ambientes com alto volume de acesso interno e menor      depend√™ncia de conectividade externa.

- Banco de dados na nuvem:
    Solu√ß√µes em nuvem oferecem maior flexibilidade e disponibilidade, o modelo de cobran√ßa por demanda reduz o custo inicial e possibilita um controle mais eficiente do or√ßamento, com escalabilidade praticamente      autom√°tica conforme o crescimento do projeto. Al√©m disso, os servi√ßos em nuvem geralmente incluem atualiza√ß√µes e suporte t√©cnico cont√≠nuo, o que reduz a necessidade de equipe t√©cnica dedicada.

- Conclus√£o:
    Para o nosso projeto, os bancos de dados na nuvem apresentam maior viabilidade financeira e operacional, oferecendo uma solu√ß√£o escal√°vel, com alta disponibilidade e menor custo inicial. J√° os bancos de dados     locais podem ser considerados em situa√ß√µes espec√≠ficas que demandem desempenho interno superior, desde que se justifique o investimento necess√°rio.

4) Qual √© o potencial de uso de servi√ßos em nuvem (como AWS EC2, RDS, Lambda ou similares) na arquitetura proposta, mesmo que simulados na etapa atual?

A solu√ß√£o utilizar√° servi√ßos em nuvem da AWS para garantir escalabilidade, baixo custo inicial e integra√ß√£o com IA. As principais escolhas s√£o:
AWS IoT Core: Substitui servidores MQTT locais, gerenciando conex√µes dos sensores ESP32 com autentica√ß√£o segura (TLS).
Amazon RDS (PostgreSQL): Armazena dados processados com alta disponibilidade e backups autom√°ticos.
AWS Lambda: Executa modelos leves de Machine Learning (ex: detec√ß√£o de anomalias) sem custo quando ocioso.
Amazon EC2: Roda modelos complexos (ex: TabTransformer) em inst√¢ncias escal√°veis.
Por que nuvem?
Custo reduzido: Camada gratuita da AWS permite testes sem investimento inicial.
Pronto para produ√ß√£o: A mesma arquitetura escala para cen√°rios reais sem modifica√ß√µes.
Simula√ß√£o f√°cil: Dados simulados (ex: gerados com Pandas) podem ser enviados para a AWS IoT Core como se fossem de sensores reais.
Cen√°rio realista: Para 10 sensores enviando dados a cada 5 segundos, o custo estimado √© de US$ 50-100/m√™s ‚Äì vi√°vel mesmo para pequenas ind√∫strias.

5) Como os dados ser√£o processados e analisados? Quais algoritmos de Machine Learning ser√£o utilizados?

- Processamento de dados:    Os dados coletados dos sensores ser√£o processados em tempo real utilizando Python, com bibliotecas como NumPy, Pandas e SciPy. O processamento incluir√° etapas como limpeza, transforma√ß√£o, integra√ß√£o e filtragem:

    Limpeza: Esta etapa envolve a remo√ß√£o de dados err√¥neos ou inconsistentes, como valores ausentes, duplicados ou fora de contexto. O objetivo √© garantir que os dados sejam precisos e representem a realidade do       que est√° sendo medido pelos sensores.
  
    Transforma√ß√£o: Nessa fase, os dados s√£o convertidos em formatos ou escalas mais adequados para an√°lise. Isso pode incluir a normaliza√ß√£o de valores, a convers√£o de vari√°veis categ√≥ricas em num√©ricas ou a            aplica√ß√£o de fun√ß√µes matem√°ticas para ajustar os dados.
  
    Integra√ß√£o: Caso os dados venham de diferentes fontes ou sensores, a integra√ß√£o combina essas informa√ß√µes em um √∫nico conjunto, garantindo que todas as vari√°veis relevantes sejam consideradas de forma coesa e       sem sobreposi√ß√£o.
  
    Filtragem: Nessa etapa, s√£o selecionados apenas os dados relevantes para o objetivo da an√°lise. Isso pode envolver a remo√ß√£o de valores fora de um intervalo espec√≠fico ou a escolha de dados de interesse com         base em crit√©rios predefinidos.

    Essas etapas garantir√£o que os dados estejam preparados de forma eficiente para as an√°lises e modelagens posteriores.

- An√°lise de dados:    A an√°lise dos dados ser√° realizada utilizando algoritmos de Machine Learning, com uma combina√ß√£o de modelos para tratamento em tempo real (ou em curtos intervalos de tempo) e modelos mais         robustos para volumes maiores de dados.

    Para dados processados em tempo real ou em curtos per√≠odos de tempo (algumas vezes ao dia), ser√° utilizada uma combina√ß√£o dos modelos Random Forest e Isolation Forest, que rodar√£o localmente, oferecendo             respostas r√°pidas e eficazes.

    J√° para grandes volumes de dados acumulados ao longo de per√≠odos mais longos (a definir com o cliente), a an√°lise ser√° feita utilizando modelos robustos, como o TabTransformer ou o     XGBoost, executados em        nuvem.
  
    Esses modelos s√£o capazes de lidar com grandes quantidades de dados e oferecem uma an√°lise detalhada e precisa. Com a divis√£o entre modelos para an√°lise em tempo real e modelos voltados a grandes volumes de         dados, o sistema oferecer√° maior flexibilidade e efici√™ncia, entregando respostas r√°pidas quando necess√°rio e an√°lises aprofundadas para o planejamento estrat√©gico.

- Predi√ß√£o:    Os modelos de Machine Learning ser√£o utilizados para prever eventos futuros com base nos dados dos sensores. As previs√µes geradas poder√£o acionar alertas autom√°ticos, alimentar an√°lises e gerar informa√ß√µes simples no dashboard interativo, al√©m de embasar an√°lises mais complexas para decis√µes espec√≠ficas, como determinar se vale a pena realizar uma manuten√ß√£o e qual o melhor momento para isso.

- Visualiza√ß√£o de dados:    A visualiza√ß√£o ser√° feita com o uso de bibliotecas como Matplotlib e Seaborn. Gr√°ficos e dashboards ser√£o utilizados para apresentar os resultados das an√°lises em tempo real e as previs√µes geradas pelos modelos. Esses recursos permitir√£o aos usu√°rios monitorar as informa√ß√µes de forma eficiente, tanto para a√ß√µes imediatas quanto para o planejamento de longo prazo.

- Alertas autom√°ticos:    Os alertas autom√°ticos ser√£o acionados com base nas previs√µes dos modelos de Machine Learning. Eles poder√£o ser enviados por e-mail, SMS ou por meio de notifica√ß√µes em um aplicativo, permitindo uma resposta r√°pida. Esses alertas se subdividem em dois tipos: alertas de status em tempo real, gerados pelos modelos mais leves, e alertas e relat√≥rios mais completos, baseados em an√°lises de longo prazo realizadas pelos modelos mais robustos.

## Esbo√ßo da arquitetura
<p align="center">
<img src="assets/diagrama3.jpg" alt="Arquitetura do projeto" border="0" width=80% height=80% id="img123"></a>
</p>


## Estrat√©gia de coleta de dados

R: Inicialmente, os dados poder√£o ser coletados de forma simulada, ou seja, utilizando scripts que geram dados artificiais com base em faixas realistas, 
padr√µes esperados ou hist√≥ricos de sensores. Essa abordagem √© √∫til durante a fase de desenvolvimento e testes, enquanto o hardware (como os sensores ESP32) 
ainda n√£o estiver plenamente operacional ou dispon√≠vel fisicamente.

Posteriormente, a coleta passar√° a ser planejada e realizada com dispositivo f√≠sicos, como o microcontrolador ESP32, conectado a diversos sensores (de movimento, temperatura, 
umidade, entre outros). O ESP32 atuar√° como um cliente MQTT, enviando dados em tempo real para um servidor MQTT. Esse servidor ser√° respons√°vel por distribuir 
as mensagens aos servi√ßos interessados, incluindo os respons√°veis por armazenar, processar e analisar os dados.

Etapas da estrat√©gia de coleta:

1. Coleta (Simulada ou Planejada):
   - Simulada: Gera√ß√£o de dados via scripts Python, com base em par√¢metros pr√©-definidos.
   - Planejada (real): Sensores f√≠sicos conectados a microcontroladores (ESP32), enviando dados via MQTT.

2. Transmiss√£o:
   - Protocolo MQTT ser√° usado para transmitir os dados do ESP32 para o servidor central.

3. Armazenamento:
   - Os dados poder√£o ser armazenados em bancos de dados relacionais (PostgreSQL, Oracle, Amazon RDS) ou NoSQL (Firebase), dependendo da necessidade de estrutura√ß√£o, escalabilidade e tempo de consulta.

4. Processamento:
   - O processamento ocorrer√° localmente ou na nuvem utilizando bibliotecas como NumPy, Pandas e SciPy, realizando etapas de limpeza, transforma√ß√£o, integra√ß√£o e filtragem.
   - Os dados tamb√©m ser√£o enviados para APIs com modelos de IA, conforme demonstrado no "<a href="#img123">Esbo√ßo da arquitetura</a>".

## Plano inicial de desenvolvimento

 ‚úÖ Fase 1: Coleta de Dados
- **Membro respons√°vel:** Alice Caroline  
- üìÜ *13 de Maio a 9 de Junho*
- Tarefas:
  - Coletar dados via MQTT usando ESP32
  - Armazenar em banco relacional ou NoSQL
  - Processamento inicial com Python (NumPy, Pandas, SciPy)

---

 üìä Fase 2: An√°lise de Dados
- **Membros respons√°veis:** Vitor Albuquerque e Leonardo Sampaio
- üìÜ *10 de Junho a 9 de Julho*
- Tarefas:
  - An√°lise com regress√£o, √°rvore de decis√£o e redes neurais
  - Visualiza√ß√£o com Matplotlib e Seaborn
  - Cria√ß√£o de dashboards com insights

---

 üîÆ Fase 3: Predi√ß√£o
- **Membro respons√°vel:** Vitor Albuquerque
- üìÜ *15 de Julho a 18 de Agosto*
- Tarefas:
  - Modelos preditivos com alertas autom√°ticos
  - Envio de alertas por email, SMS ou app

---

 üîå Fase 4: Integra√ß√£o com APIs
- **Membro respons√°vel:** Lucas Basseto
- üìÜ *18 de Agosto a 15 de Setembro*
- Tarefas:
  - Integra√ß√£o com APIs RESTful usando Flask ou FastAPI
  - Documenta√ß√£o com Swagger ou Postman
  - Testes automatizados com `pytest` ou `unittest`

---

 üê≥ Fase 5: Cont√™ineres Docker
- **Membro respons√°vel:** Pedro Lucas
- üìÜ *16 de Setembro a 13 de Outubro*
- Tarefas:
  - Dockerfile para cada servi√ßo
  - Orquestra√ß√£o com Docker Compose
  - Testes automatizados dos containers

---

 ‚úÖ Fase 6: Testes Automatizados
- **Membros respons√°veis:** Pedro Lucas e Lucas Basseto
- üìÜ *14 de Outubro a 03 de Novembro*
- Tarefas:
  - Testes unit√°rios, integra√ß√£o e aceita√ß√£o
  - CI para rodar testes automaticamente a cada commit

---

 üìö Fase 7: Documenta√ß√£o
- **Membro respons√°vel:** Leonardo Sampaio
- üìÜ *04 de Novembro a 17 de Novembro*
- Tarefas:
  - Documenta√ß√£o clara e atualizada
  - Uso de ferramentas autom√°ticas de gera√ß√£o de doc

---

 üîß Fase 8: Melhorias
- **Membros respons√°veis:** Todos do grupo
- üìÜ *20 de novembro a 7 de dezembro*
- Tarefas:
  - Testes de carga e estresse
  - Monitoramento e ajustes
  - Melhorias na interface



## üóÉ Hist√≥rico de lan√ßamentos

* 0.1.0 - 04/05/2025
    *

## üìã Licen√ßa

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> est√° licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>


