# FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

# Sprint 1 - Reply 

## Nome do grupo

## üë®‚Äçüéì Integrantes: 
- <a href="https://www.linkedin.com/in/alice-caroline-marinho">Alice Caroline Marinho de Assis</a>
- <a href="https://www.linkedin.com/in/pedro-lucas-458917207/">Pedro Lucas Tostes Silva</a>
- <a href="https://www.linkedin.com/company/inova-fusca">Nome do integrante 3</a> 
- <a href="https://www.linkedin.com/company/inova-fusca">Nome do integrante 4</a> 
- <a href="https://www.linkedin.com/company/inova-fusca">Nome do integrante 5</a>

## üë©‚Äçüè´ Professores:
### Tutor(a) 
- <a href="https://www.linkedin.com/company/inova-fusca">Lucas Gomes Moreira</a>
### Coordenador(a)
- <a href="https://www.linkedin.com/company/inova-fusca">Andr√© Godoi Chiovato</a>


## üìú Descri√ß√£o

Este projeto visa o desenvolvimento de uma solu√ß√£o com foco em controle inteligente de processos, monitoramento, dashboards, alertas autom√°ticos e sistemas de predi√ß√£o. Com isso, busca ajudar seus clientes a alcan√ßarem excel√™ncia operacional, digitalizando seus ambientes e integrando dispositivos f√≠sicos e digitais para gerar dados e insights valiosos em tempo real.

## üõ† Tecnologias utilizadas
- Python
- NumPy
- Pandas
- Matplotlib
- Scipy
- Seaborn
- C++
- Docker
- Oracle Database / PostgreSQL / Amazon RDS ou Firebase
- MqTT
- TensorFlow / PyTorch

## Considera√ß√µes

**Como os dados ser√£o coletados a partir de sensores?**

**R:** Os dados ser√£o coletados a partir de sensores conectados a um ESP32 utilizando o protocolo MQTT. O ESP32 atuar√° como um cliente MQTT, publicando os dados dos sensores em t√≥picos espec√≠ficos. O servidor MQTT, que pode ser hospedado em um servi√ßo de nuvem ou em um servidor local, receber√° essas mensagens e as encaminhar√° para uma fila a qual distribuir√° para os servi√ßos inscritos.

**Onde os dados ser√£o armazenados?**

**R:** Os dados ser√£o armazenados em um banco de dados em nuvem utilizando Amazon RDS (PostgreSQL) para dados estruturados (como m√©tricas de sensores e logs) e Amazon S3 para dados brutos e arquivos tempor√°rios.
Por que essa escolha?
Escalabilidade Autom√°tica: O Amazon RDS ajusta capacidade conforme a demanda sem downtime, crucial para linhas de produ√ß√£o com picos de opera√ß√£o.
Alta Disponibilidade: Replica√ß√£o multi-AZ garante 99,99% de uptime (SLA AWS), evitando paradas n√£o planejadas.
Integra√ß√£o com IA: Compatibilidade nativa com servi√ßos AWS como Lambda e SageMaker, facilitando a implementa√ß√£o de modelos de ML.
Custo-Benef√≠cio: Amazon S3 armazena dados brutos a baixo custo (US$ 0,023/GB/m√™s), enquanto RDS oferece backups automatizados gratuitos.

**Como ser√° feita a integra√ß√£o com modelos de IA?**

**R:** A integra√ß√£o com modelos de IA ser√° realizada atrav√©s de APIs RESTful. Os dados coletados dos sensores ser√£o enviados para um servi√ßo que executar√° os modelos de IA, que podem ser implementados em Python utilizando bibliotecas como TensorFlow ou PyTorch. Os resultados das previs√µes ser√£o retornados para o sistema e poder√£o ser armazenados no banco de dados ou utilizados para acionar alertas autom√°ticos.

**Onde ocorrer√° o processamento?**

**R:** O processamento dos dados coletados dos sensores ocorrer√° em um servidor local ou na nuvem, dependendo da arquitetura escolhida. O uso de cont√™ineres Docker permitir√° que o sistema seja facilmente escal√°vel e port√°til, facilitando a implementa√ß√£o em diferentes ambientes. A escolha entre processamento local ou na nuvem depender√° das necessidades espec√≠ficas da empresa, da infraestrutura dispon√≠vel e preocupa√ß√£o com o sigilo dos dados.

## Requisitos T√©cnicos e Funcionais

1) Linguagens e ferramentas adequadas para an√°lise de dados e Machine Learning

- Python: Linguagem de programa√ß√£o amplamente utilizada para an√°lise de dados e Machine Learning, com bibliotecas como NumPy, Pandas, Matplotlib e Scipy.

2) Como os dados ser√£o coletados, incluindo o tipo de coleta (simulada ou planejada via sensores como ESP32), armazenados e processados?

- Coleta de dados: Os dados ser√£o coletados a partir de sensores conectados a um ESP32 utilizando o protocolo MQTT. O ESP32 atuar√° como um cliente MQTT, publicando os dados dos sensores em t√≥picos espec√≠ficos. O servidor MQTT, que pode ser hospedado em um servi√ßo de nuvem ou em um servidor local, receber√° essas mensagens e as encaminhar√° para uma fila a qual distribuir√° para os servi√ßos inscritos. Um desses servi√ßos ser√° o de armazenagem de dados, que cuidar√° de sua armazenagem em um dos bancos de dados citados anteriormente.

3) Qual √© a justificativa para a escolha de um banco de dados local ou na n√∫vem? Qual √© a sua escabilidade e viabilidade em rela√ß√£o ao projeto?

- A escolha entre um banco de dados local ou na nuvem deve considerar as necessidades espec√≠ficas do projeto, a infraestrutura dispon√≠vel e o n√≠vel de exig√™ncia quanto disponibilidade dos dados.

- Banco de dados local:
    A implementa√ß√£o local demanda um investimento inicial elevado, com custos associados √† aquisi√ß√£o de servidores, infraestrutura de TI e m√£o de obra especializada para instala√ß√£o e manuten√ß√£o. Al√©m disso, a         escalabilidade tende a ser limitada, exigindo novos aportes sempre que for necess√°rio expandir a capacidade. No entanto, pode apresentar melhor desempenho em ambientes com alto volume de acesso interno e menor      depend√™ncia de conectividade externa.

- Banco de dados na nuvem:
    Solu√ß√µes em nuvem oferecem maior flexibilidade e disponibilidade, o modelo de cobran√ßa por demanda reduz o custo inicial e possibilita um controle mais eficiente do or√ßamento, com escalabilidade praticamente      autom√°tica conforme o crescimento do projeto. Al√©m disso, os servi√ßos em nuvem geralmente incluem atualiza√ß√µes e suporte t√©cnico cont√≠nuo, o que reduz a necessidade de equipe t√©cnica dedicada.

- Conclus√£o:
    Para o nosso projeto, os bancos de dados na nuvem apresentam maior viabilidade financeira e operacional, oferecendo uma solu√ß√£o escal√°vel, com alta disponibilidade e menor custo inicial. J√° os bancos de dados     locais podem ser considerados em situa√ß√µes espec√≠ficas que demandem desempenho interno superior, desde que se justifique o investimento necess√°rio.

4) Qual √© o potencial de uso de servi√ßos em nuvem (como AWS EC2, RDS, Lambda ou similares) na arquitetura proposta, mesmo que simulados na etapa atual?

A solu√ß√£o utilizar√° servi√ßos em nuvem da AWS para garantir escalabilidade, baixo custo inicial e integra√ß√£o com IA. As principais escolhas s√£o:
AWS IoT Core: Substitui servidores MQTT locais, gerenciando conex√µes dos sensores ESP32 com autentica√ß√£o segura (TLS).
Amazon RDS (PostgreSQL): Armazena dados processados com alta disponibilidade e backups autom√°ticos.
AWS Lambda: Executa modelos leves de Machine Learning (ex: detec√ß√£o de anomalias) sem custo quando ocioso.
Amazon EC2: Roda modelos complexos (ex: TabTransformer) em inst√¢ncias escal√°veis.
Por que nuvem?
Custo reduzido: Camada gratuita da AWS permite testes sem investimento inicial.
Pronto para produ√ß√£o: A mesma arquitetura escala para cen√°rios reais sem modifica√ß√µes.
Simula√ß√£o f√°cil: Dados simulados (ex: gerados com Pandas) podem ser enviados para a AWS IoT Core como se fossem de sensores reais.
Cen√°rio realista: Para 10 sensores enviando dados a cada 5 segundos, o custo estimado √© de US$ 50-100/m√™s ‚Äì vi√°vel mesmo para pequenas ind√∫strias.

5) Como os dados ser√£o processados e analisados? Quais algoritmos de Machine Learning ser√£o utilizados?

- Processamento de dados:    Os dados coletados dos sensores ser√£o processados em tempo real utilizando Python, com bibliotecas como NumPy, Pandas e SciPy. O processamento incluir√° etapas como limpeza, transforma√ß√£o, integra√ß√£o e filtragem:

    Limpeza: Esta etapa envolve a remo√ß√£o de dados err√¥neos ou inconsistentes, como valores ausentes, duplicados ou fora de contexto. O objetivo √© garantir que os dados sejam precisos e representem a realidade do       que est√° sendo medido pelos sensores.
  
    Transforma√ß√£o: Nessa fase, os dados s√£o convertidos em formatos ou escalas mais adequados para an√°lise. Isso pode incluir a normaliza√ß√£o de valores, a convers√£o de vari√°veis categ√≥ricas em num√©ricas ou a            aplica√ß√£o de fun√ß√µes matem√°ticas para ajustar os dados.
  
    Integra√ß√£o: Caso os dados venham de diferentes fontes ou sensores, a integra√ß√£o combina essas informa√ß√µes em um √∫nico conjunto, garantindo que todas as vari√°veis relevantes sejam consideradas de forma coesa e       sem sobreposi√ß√£o.
  
    Filtragem: Nessa etapa, s√£o selecionados apenas os dados relevantes para o objetivo da an√°lise. Isso pode envolver a remo√ß√£o de valores fora de um intervalo espec√≠fico ou a escolha de dados de interesse com         base em crit√©rios predefinidos.

    Essas etapas garantir√£o que os dados estejam preparados de forma eficiente para as an√°lises e modelagens posteriores.

- An√°lise de dados:    A an√°lise dos dados ser√° realizada utilizando algoritmos de Machine Learning, com uma combina√ß√£o de modelos para tratamento em tempo real (ou em curtos intervalos de tempo) e modelos mais         robustos para volumes maiores de dados.

    Para dados processados em tempo real ou em curtos per√≠odos de tempo (algumas vezes ao dia), ser√° utilizada uma combina√ß√£o dos modelos Random Forest e Isolation Forest, que rodar√£o localmente, oferecendo             respostas r√°pidas e eficazes.

    J√° para grandes volumes de dados acumulados ao longo de per√≠odos mais longos (a definir com o cliente), a an√°lise ser√° feita utilizando modelos robustos, como o TabTransformer ou o     XGBoost, executados em        nuvem.
  
    Esses modelos s√£o capazes de lidar com grandes quantidades de dados e oferecem uma an√°lise detalhada e precisa. Com a divis√£o entre modelos para an√°lise em tempo real e modelos voltados a grandes volumes de         dados, o sistema oferecer√° maior flexibilidade e efici√™ncia, entregando respostas r√°pidas quando necess√°rio e an√°lises aprofundadas para o planejamento estrat√©gico.

- Predi√ß√£o:    Os modelos de Machine Learning ser√£o utilizados para prever eventos futuros com base nos dados dos sensores. As previs√µes geradas poder√£o acionar alertas autom√°ticos, alimentar an√°lises e gerar informa√ß√µes simples no dashboard interativo, al√©m de embasar an√°lises mais complexas para decis√µes espec√≠ficas, como determinar se vale a pena realizar uma manuten√ß√£o e qual o melhor momento para isso.

- Visualiza√ß√£o de dados:    A visualiza√ß√£o ser√° feita com o uso de bibliotecas como Matplotlib e Seaborn. Gr√°ficos e dashboards ser√£o utilizados para apresentar os resultados das an√°lises em tempo real e as previs√µes geradas pelos modelos. Esses recursos permitir√£o aos usu√°rios monitorar as informa√ß√µes de forma eficiente, tanto para a√ß√µes imediatas quanto para o planejamento de longo prazo.

- Alertas autom√°ticos:    Os alertas autom√°ticos ser√£o acionados com base nas previs√µes dos modelos de Machine Learning. Eles poder√£o ser enviados por e-mail, SMS ou por meio de notifica√ß√µes em um aplicativo, permitindo uma resposta r√°pida. Esses alertas se subdividem em dois tipos: alertas de status em tempo real, gerados pelos modelos mais leves, e alertas e relat√≥rios mais completos, baseados em an√°lises de longo prazo realizadas pelos modelos mais robustos.

## Esbo√ßo da arquitetura
<p align="center">
<img src="assets/diagrama2.jpg" alt="Arquitetura do projeto" border="0" width=80% height=80%></a>
</p>

## Explica√ß√£o da estrat√©gia de coleta de dados

N√£o entendi, confirmar com o professor

## Plano inicial de desenvolvimento

 ‚úÖ Fase 1: Coleta de Dados
- **Membro respons√°vel:** Alice Caroline  
- üìÜ *13 de Maio a 9 de Junho*
- Tarefas:
  - Coletar dados via MQTT usando ESP32
  - Armazenar em banco relacional ou NoSQL
  - Processamento inicial com Python (NumPy, Pandas, SciPy)

---

 üìä Fase 2: An√°lise de Dados
- **Membros respons√°veis:** Vitor Albuquerque e Leonardo Sampaio
- üìÜ *10 de Junho a 9 de Julho*
- Tarefas:
  - An√°lise com regress√£o, √°rvore de decis√£o e redes neurais
  - Visualiza√ß√£o com Matplotlib e Seaborn
  - Cria√ß√£o de dashboards com insights

---

 üîÆ Fase 3: Predi√ß√£o
- **Membro respons√°vel:** Vitor Albuquerque
- üìÜ *15 de Julho a 18 de Agosto*
- Tarefas:
  - Modelos preditivos com alertas autom√°ticos
  - Envio de alertas por email, SMS ou app

---

 üîå Fase 4: Integra√ß√£o com APIs
- **Membro respons√°vel:** Lucas Basseto
- üìÜ *18 de Agosto a 15 de Setembro*
- Tarefas:
  - Integra√ß√£o com APIs RESTful usando Flask ou FastAPI
  - Documenta√ß√£o com Swagger ou Postman
  - Testes automatizados com `pytest` ou `unittest`

---

 üê≥ Fase 5: Cont√™ineres Docker
- **Membro respons√°vel:** Pedro Lucas
- üìÜ *16 de Setembro a 13 de Outubro*
- Tarefas:
  - Dockerfile para cada servi√ßo
  - Orquestra√ß√£o com Docker Compose
  - Testes automatizados dos containers

---

 ‚úÖ Fase 6: Testes Automatizados
- **Membros respons√°veis:** Pedro Lucas e Lucas Basseto
- üìÜ *14 de Outubro a 03 de Novembro*
- Tarefas:
  - Testes unit√°rios, integra√ß√£o e aceita√ß√£o
  - CI para rodar testes automaticamente a cada commit

---

 üìö Fase 7: Documenta√ß√£o
- **Membro respons√°vel:** Leonardo Sampaio
- üìÜ *04 de Novembro a 17 de Novembro*
- Tarefas:
  - Documenta√ß√£o clara e atualizada
  - Uso de ferramentas autom√°ticas de gera√ß√£o de doc

---

 üîß Fase 8: Melhorias
- **Membros respons√°veis:** Todos do grupo
- üìÜ *20 de novembro a 7 de dezembro*
- Tarefas:
  - Testes de carga e estresse
  - Monitoramento e ajustes
  - Melhorias na interface



## üóÉ Hist√≥rico de lan√ßamentos

* 0.1.0 - 04/05/2025
    *

## üìã Licen√ßa

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> est√° licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>


